{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "IO_Homework.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [
        "bWD3kcZEncnl"
      ],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 2",
      "language": "python",
      "name": "python2"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8pdL8Cutncm2",
        "colab_type": "text"
      },
      "source": [
        "IO Homework\n",
        "=======\n",
        "\n",
        "\n",
        "### Instructions / Notes:\n",
        "\n",
        "* This homework, as with the rest of the homeworks in the course, is *not* graded. Although you do not need to turn it in, we expect every student to complete it (and material from it will show up on the final)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aroefliCncm2",
        "colab_type": "text"
      },
      "source": [
        "Problem 1: External Merge Sort\n",
        "------------------------\n",
        "\n",
        "In this problem we'll explore an optimization often referred to as **_double buffering_**, which we'll use to speed up the **external merge sort algorithm** we saw in _Lecture 13_.\n",
        "\n",
        "Recall that _sequential IO_ (i.e. involving reading from / writing to consecutive pages) is generally much faster that _random access IO_ (any reading / writing that is not sequential). Additionally, on newer memory technologies like SSD reading data can be faster than writing data (if you want to read more about SSD access patterns look [here](http://codecapsule.com/2014/02/12/coding-for-ssds-part-5-access-patterns-and-system-optimizations/). \n",
        "\n",
        "For example, if we read 8 consecutive pages from file $A$, this should be much faster than reading 2 pages from $A$, then 4 pages from file $B$, then 2 pages from $A$.\n",
        "\n",
        "**In this problem, we will begin to model this, by assuming that 8 sequential _READS_ are \"free\", i.e. the total cost of $8$ sequential reads is $1$ IO. We will also assume that the writes are always twice as expensive as a read. Sequential writes are never free, therefore the cost of $N$ writes is always $2N$.**\n",
        "\n",
        "### Other important notes:\n",
        "* **NO REPACKING:** Consider the external merge sort algorithm using the basic optimizations we present in Lecture 13, but do not use the repacking optimization covered in Lecture 13.\n",
        "* **ONE BUFFER PAGE RESERVED FOR OUTPUT:** Assume we use one page for output in a merge, e.g. a $B$-way merge would require $B+1$ buffer pages\n",
        "* **REMEMBER TO ROUND:** Take ceilings (i.e. rounding up to nearest integer values) into account in this problem.  Note that we have sometimes omitted these (for simplicity) in lecture.\n",
        "* **Consider worst case cost:** In other words, if 2 reads _could happen_ to be sequential, but in general might not be, consider these random IO"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cngO11YMncm4",
        "colab_type": "text"
      },
      "source": [
        "### Part (a)\n",
        "\n",
        "Consider a modification of the external merge sort algorithm where **reads are always read in 8-page chunks (i.e. 8 pages sequentially at a time)** so as to take advantage of sequential reads. Calculate the cost of performing the external merge sort for a setup having $B+1=40$ buffer pages and an unsorted input file with $320$ pages.\n",
        "\n",
        "Show the steps of your work and make sure to explain your reasoning by writing them as python comments above the final answers.\n",
        "\n",
        "#### Part (a.i)\n",
        "\n",
        "What is the **exact** IO cost of spliting and sorting the files? As is standard we want runs of size $B+1$."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mWqMuqavncm5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "io_split_sort = None  # TODO"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lB7Tdez7ncm7",
        "colab_type": "text"
      },
      "source": [
        "#### Part (a.ii)\n",
        "\n",
        "After the file is split and sorted, we can merge $n$ runs into 1 using the merge process. What is largest $n$ we could have, given reads are always read in 8-page chunks? Note: this is known as the arity of the merge."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rIOh2kAcncm8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "merge_arity = None  # TODO"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tiV5MG5yncm_",
        "colab_type": "text"
      },
      "source": [
        "#### Part (a.iii)\n",
        "\n",
        "How many passes of merging are required?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ji78tw5yncnA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "merge_passes = None   # TODO"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lAp_aEW0ncnD",
        "colab_type": "text"
      },
      "source": [
        "#### Part (a.iv)\n",
        "\n",
        "What is the IO cost of the first pass of merging? Note: the highest arity merge should always be used."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "46EUJ9nGncnE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "merge_pass_1 = None  # TODO"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GJ3TYX53ncnG",
        "colab_type": "text"
      },
      "source": [
        "#### Part (a.v)\n",
        "\n",
        "What is the total IO cost of running this external merge sort algorithm? **Do not forget to add in the remaining passes (if any) of merging.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IlyGoa6yncnH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "total_io = None  # TODO"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XTC7qr9TncnJ",
        "colab_type": "text"
      },
      "source": [
        "### Part (b)\n",
        "\n",
        "Now, we'll generalize the reasoning above by writing a python function that computes the _approximate_* cost of performing this version of external merge sort for a setup having $B+1$ buffer pages, a file with $N$ pages, and where we now read in $P$-page chunks (replacing our fixed 8 page chunks in Part (a)).\n",
        "\n",
        "**Note: our approximation will be a small one- for simplicity, we'll assume that each pass of the merge phase has the same IO cost, when actually it can vary slightly... Everything else will be exact given our model!* \n",
        "\n",
        "We'll call this function `external_merge_sort_cost(B,N,P)`, and we'll compute it as the product of the cost of reading in and writing out all the data (which we do each pass), and the number of passes we'll have to do.\n",
        "\n",
        "Even though this is an approximation, **make sure to take care of floor / ceiling operations- i.e. rounding down / up to integer values properly!**\n",
        "\n",
        "**Importantly, to simplify your calculations: Your function will only be evaluated on cases where the following hold:**\n",
        "* **(B + 1) % P == 0** (i.e. the buffer size is divisible by the chunk size)\n",
        "* **N % (B + 1) == 0** (i.e. the file size is divisible by the buffer size)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X3cnaaLdncnL",
        "colab_type": "text"
      },
      "source": [
        "#### Part (b.i)\n",
        "\n",
        "First, let's write a python function that computes the **exact** total IO cost to create the initial runs:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7FeEVhlPncnM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def cost_initial_runs(B, N, P):\n",
        "    return None  # TODO"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jTVkvhdNncnR",
        "colab_type": "text"
      },
      "source": [
        "#### Part (b.ii)\n",
        "\n",
        "Next, let's write a python function that computes the _approximate_* total IO cost to read in and then write out all the data during one pass of the merge:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DICG9-9JncnS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def cost_per_pass(B, N, P):\n",
        "    return None  # TODO"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YQTK7N6gncnV",
        "colab_type": "text"
      },
      "source": [
        "**Note that this is an approximation: when we read in chunks during the merge phase, the cost per pass actually varies slightly due to 'rounding issues'  when the file is split up into runs... but this is a small difference*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oK14w1CwncnW",
        "colab_type": "text"
      },
      "source": [
        "#### Part (b.iii)\n",
        "\n",
        "Next, let's write a python function that computes the **exact** total number of passes we'll need to do"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6aX2X3H9ncnW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import math\n",
        "def num_passes(B, N, P):\n",
        "    return None  # TODO"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "19nwZgQ9ncnb",
        "colab_type": "text"
      },
      "source": [
        "Finally, our total cost function is:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nrYqa1ZFncnc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def external_merge_sort_cost(B, N, P):\n",
        "    return None  # TODO"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AAxywkxPncnd",
        "colab_type": "text"
      },
      "source": [
        "### Part (c)\n",
        "\n",
        "For $B + 1 =100$ and $N=900$, find the optimal $P$ according to your IO cost equation above.  Return both the optimal $P$ value (`P_opt`) and the list of tuples **_for feasible values of $P$_** that would generate a plot of P vs. IO cost, at resolution $=1$(every value of P), stored as `points`:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0FIU5EBincne",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "B = 99\n",
        "N = 900\n",
        "\n",
        "points = [None]  # TODO"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hWXoDk6Hncni",
        "colab_type": "code",
        "outputId": "924a712e-373d-4abf-e970-2aa261a8447d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 296
        }
      },
      "source": [
        "# Shell code for plotting in matplotlib\n",
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Plot\n",
        "plt.plot(*zip(*points))\n",
        "plt.title(\"IO Cost vs. Page chunk size\")\n",
        "plt.ylabel(\"Cost in IO\")\n",
        "plt.xlabel(\"Page chunk size: P\")\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYsAAAEVCAYAAAARjMm4AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nsIiIiKKERUREFCUsIiKiKGERERFF/wkcrR+JWHzVjwAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<matplotlib.figure.Figure at 0x7f894c081350>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FUN_xnlbL-7s",
        "colab_type": "text"
      },
      "source": [
        "What is the optimal Page chunk size, $P_{opt}$? Explain the graph's shape and what happens at $P_{opt}+1$."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2wpLGafcNA-K",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "P_opt = None  # TODO\n",
        "\n",
        "# Explanation: TODO"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8-j7RResncnk",
        "colab_type": "text"
      },
      "source": [
        "Problem 2: IO Cost Models\n",
        "--------------------------------------\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bWD3kcZEncnl",
        "colab_type": "text"
      },
      "source": [
        "In this problem we consider different join algorithms when joining relations $R(A,B)$, $S(B,C)$, and $T(C,D)$. We want to investigate the cost of various pairwise join plans and try to determine the best join strategy given some conditions.\n",
        "\n",
        "Specifically, for each part of this question, we are intereseted determining some (or all) of the following variables:\n",
        "\n",
        "* `P_R`: Number of pages of $R$\n",
        "* `P_S`: Number of pages of $S$\n",
        "* `P_RS`: Number of pages of output (and input) $RS$\n",
        "* `P_T`: Number of pages of $T$\n",
        "* `P_RST`: Number of pages of output (and input) $RS$\n",
        "* `B`: Number of pages in buffer\n",
        "* `IO_cost_join1`: Total IO cost of first join\n",
        "* `IO_cost_join2`: Total IO cost of second join\n",
        "\n",
        "#### Note:\n",
        "* ** The output of join1 is always fed as one of the inputs to join 2 ** \n",
        "* **Use the \"vanilla\" versions of the algorithms as presented in lecture, _i.e. without any of the optimizations we mentioned_**\n",
        "* **Again assume we use one page for output, as in lecture!**\n",
        "* ** The abbreviates for the joins used are Sort-Merge Join (SMJ), Hash Join (HJ), and Block Nested Loop Join (BNLJ). **"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lLYhOfjwncnm",
        "colab_type": "text"
      },
      "source": [
        "### Part (a)\n",
        "\n",
        "Given:\n",
        "* `P_R`: 20\n",
        "* `P_S`: 200\n",
        "* `P_T`: 2000\n",
        "* `P_RS`: 100\n",
        "* `P_ST`: 1000\n",
        "* `P_RST`: 500\n",
        "* `B`: 32\n",
        "\n",
        "Compute the IO cost for the following query plans:\n",
        "\n",
        "* IO_Cost_HJ_1 where only hash join is used, $join1 = R(a,b),S(b,c)$ and $join2 = join1(a,b,c),T(c,d)$\n",
        "* IO_Cost_HJ_2 where only hash join is used, $join1 = T(c,d),S(b,c)$ and $join2 = join1(b,c,d),R(a,b)$\n",
        "* IO_Cost_SMJ_1 where only sort merge join is used, $join1 = R(a,b),S(b,c)$ and $join2 = join1(a,b,c),T(c,d)$\n",
        "* IO_Cost_SMJ_2 where only sort merge join is used, $join1 = T(c,d),S(b,c)$ and $join2 = join1(b,c,d),R(a,b)$\n",
        "* IO_Cost_BNLJ_1 where only block nested loop join is used, $join1 = R(a,b),S(b,c)$ and $join2 = join1(a,b,c),T(c,d)$\n",
        "* IO_Cost_BNLJ_2 where only block nested loop merge join is used, $join1 = T(c,d),S(b,c)$ and $join2 = join1(b,c,d),R(a,b)$\n",
        "\n",
        "**Note: again, be careful of rounding for this problem. Use ceiling/floors whenever it is necessary.**\n",
        "\n",
        "Include 1-2 sentences (as a python comment) above each answer explaining the performance for each algorithm/query plan."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RYDL2aTZHY9C",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# P_R = 20\n",
        "# P_S = 200\n",
        "# P_T = 2000\n",
        "# P_RS = 100\n",
        "# P_ST = 1000\n",
        "# P_RST = 500\n",
        "# B = 32\n",
        "\n",
        "IO_Cost_HJ_1 = None    # TODO\n",
        "\n",
        "IO_Cost_HJ_2 = None    # TODO\n",
        "\n",
        "IO_Cost_SMJ_1 = None   # TODO\n",
        "\n",
        "IO_Cost_SMJ_2 = None   # TODO\n",
        "\n",
        "IO_Cost_BNLJ_1 = None  # TODO\n",
        "\n",
        "IO_Cost_BNLJ_2 = None  # TODO"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pMmEGeSdncns",
        "colab_type": "text"
      },
      "source": [
        "### Part (b)\n",
        "\n",
        "For the query plan where $join1 = R(a,b),S(b,c)$ and $join2 = join1(a,b,c),T(c,d)$ find a configuration where using HJ for $join1$ and SMJ for $join2$ is cheaper than SMJ for $join1$ and HJ for $join2$. The output sizes you choose for `P_RS` and `P_RS` must be non-zero and feasible (e.g. the maximum output size of $join1$ is `P_R*P_S`). "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JoBx9taxHxbS",
        "colab_type": "code",
        "outputId": "ffe9a78f-72b7-4978-94cc-1fae8fc7af3c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 62
        }
      },
      "source": [
        "P_R = None    # TODO\n",
        "P_S = None    # TODO\n",
        "P_T = None    # TODO\n",
        "P_RS = None   # TODO\n",
        "P_RST = None  # TODO\n",
        "B = None      # TODO\n",
        "\n",
        "HJ_IO_Cost_join1 = 0   # TODO\n",
        "SMJ_IO_Cost_join2 = 0  # TODO\n",
        "\n",
        "SMJ_IO_Cost_join1 = 0  # TODO\n",
        "HJ_IO_Cost_join2 = 0   # TODO\n",
        "\n",
        "print 'HJ for join1, SMJ for join2: cost =', HJ_IO_Cost_join1 + SMJ_IO_Cost_join2\n",
        "print 'SMJ for join1, HJ for join2: cost =', SMJ_IO_Cost_join1 + HJ_IO_Cost_join2"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "HJ for join1, SMJ for join2: cost = 0\n",
            "SMJ for join1, HJ for join2: cost = 0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e0EjrEUPncnv",
        "colab_type": "text"
      },
      "source": [
        "Problem 3: B+ Trees\n",
        "-----------------------"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rRDW4Sryncnw",
        "colab_type": "text"
      },
      "source": [
        "In _Lecture 13_ we saw how B+ Trees (a variant of the more general class of B-Trees) can be used to build _indexes_ for quick access to structured data. In this question, you'll get more practice thinking about B+ trees."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RLDPR4vdRGNl",
        "colab_type": "text"
      },
      "source": [
        "For the rest of the question, let's consider the following scenario.  You have a database of 1 billion rows containing a unique *id* and a few other fields. You decide you want to build a B+ tree index on the *id* field of your 1 billion rows.\n",
        "\n",
        "For simplicity, let's adopt the convention that 1Gigabyte = 1e9 Bytes).\n",
        "\n",
        "Furthermore:\n",
        "\n",
        "*   Each page is exactly 4 KB (4000 Bytes)\n",
        "*   The size of each key in your B+ tree is 8 bytes\n",
        "*   The size of each pointer in your B+ tree is 8 bytes.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A5_RUqSSQ9LQ",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "## Part (a)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tvS3AHIGSjfx",
        "colab_type": "text"
      },
      "source": [
        "**Assume that we have a fill-factor of 100% on our B+ tree.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "MQ6zUinVVSnq"
      },
      "source": [
        "### Part (a.i)\n",
        "\n",
        "Each node in the B+ tree structure we build can have between $d$ and $2d$ keys, with the special case that the root node can have between $1$ and $2d$ keys. \n",
        "\n",
        "What is the maximum value of $d$ that we can use?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kehkjxtdc2fF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "max_value_of_d = None  # TODO"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b_q52Cs0eYFY",
        "colab_type": "text"
      },
      "source": [
        "### Part (a.ii)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dNOhBSznVs1O",
        "colab_type": "text"
      },
      "source": [
        "Write a python function that given (the size in bytes of each key, the size in bytes of each pointer, and the number of bytes in a page) returns the largest value of $d$ we can use for our tree.\n",
        "\n",
        "Run the following assert as well to sanity check your function.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bJxYP_OYdLa-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def maximal_degree(key_size, ptr_size, pg_size):\n",
        "  return None  # TODO"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8l_to2shdzGu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "d = maximal_degree(8, 8, 4000)\n",
        "if d != max_value_of_d:\n",
        "  raise Exception(\"Got {}, expected {}\".format(d, max_value_of_d))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "47FhdFTw1Ze8",
        "colab_type": "text"
      },
      "source": [
        "### Part (a.iii)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gTM16fw51elw",
        "colab_type": "text"
      },
      "source": [
        "Fanout is defined as the number of pointers to child nodes coming out of a node.\n",
        "\n",
        "What is the fanout for our B+ tree? "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sx-1j1uQ10LW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tree_fanout = None  # TODO"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3VQFrVfH2uPw",
        "colab_type": "text"
      },
      "source": [
        "### Part (a.iii) cont."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KJunp0RL2xGE",
        "colab_type": "text"
      },
      "source": [
        "How many index pages are required to index your 1 billion rows?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LiQs7ldp2yb4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "index_pages_required = # TODO"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ckSNSiPnebx3",
        "colab_type": "text"
      },
      "source": [
        "### Part (a.iv)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LhFKTwQBeQRP",
        "colab_type": "text"
      },
      "source": [
        "We now know what value of $d$ we are using as well as the number of index pages we need. What is the height of the B+ tree we need to build?\n",
        "\n",
        "*  The *height* of the tree is the number of levels in the B+ tree, starting from the root down to the last level before the tree points to data records.\n",
        "*   Assume that each node in the tree is full with $2d$ keys.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yV-vp8EPfuf4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "min_tree_height = None  # TODO"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xoYG7ZstkR7f",
        "colab_type": "text"
      },
      "source": [
        "## Part (b)\n",
        "\n",
        "Let's now think of the I/O costs we expect to incur on our B+ tree.  Let's still keep the assumption that the B+ tree is 100% full."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kgYMufT7klWN",
        "colab_type": "text"
      },
      "source": [
        "### Part (b.i)\n",
        "\n",
        "Your friend comes by and congratulates you on the design of your B+ tree. She claims that it's going to be really efficient because you will only need to do I/O when you fetch *data records* from disk. \n",
        "\n",
        "Let's say you are running your database on your shiny new school laptop which has 8GB of memory and infinite hard disk space.\n",
        "\n",
        "Do you correct your friend, or do you agree and join her in celebrating your awesome B+ tree?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NiBBq3GtlI1k",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "num_levels_of_tree_that_fit_in_memory = None  # TODO"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5v17vq1Doiqp",
        "colab_type": "text"
      },
      "source": [
        "### Part (b.ii)\n",
        "\n",
        "Considering only queries for records with a specific *id* or for a range of *id*s, what is the best case I/O cost and the worst case I/O cost of a query?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yIqr694qpzEa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "best_case_io_cost = None  # TODO\n",
        "\n",
        "worst_case_io_cost = None  # TODO"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xE8_0Zl7Gy5Z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}