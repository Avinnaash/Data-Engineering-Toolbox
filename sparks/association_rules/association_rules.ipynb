{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import sys\n",
    "import time\n",
    "from pyspark import SparkConf, SparkContext\n",
    "\n",
    "conf = SparkConf()\n",
    "sc = SparkContext(conf=conf)\n",
    "sc.setLogLevel(\"ERROR\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "fname = \"data/browsing.txt\"\n",
    "sessions = (sc\n",
    "    .textFile(fname)\n",
    "    # .sample(False, 0.1, 0) # uncomment this line to load a small sample only\n",
    "    .map(lambda x : x.split()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Frequent Singletons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing completed, time elapsed: 2.64s\n",
      "\n"
     ]
    }
   ],
   "source": [
    "time_start = time.time()\n",
    "\n",
    "# first pass: only keeps singleton with frequency >= 100\n",
    "freq_items_support = (sessions\n",
    "    .flatMap(lambda x : [(y, 1) for y in x])\n",
    "    .reduceByKey(lambda n1, n2 : n1 + n2)\n",
    "    .filter(lambda x : x[1] >= 100)\n",
    "    .sortByKey()\n",
    "    )\n",
    "\n",
    "freq_items = {x[0] : x[1] for x in freq_items_support.collect()}\n",
    "\n",
    "time_end = time.time()\n",
    "print(\"processing completed, time elapsed: %.2fs\\n\"%(time_end - time_start))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Frequent Pair"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_pairs(basket):\n",
    "    pairs = []\n",
    "    if len(basket) < 2: return pairs\n",
    "    for i, item_1 in enumerate(basket[:-1]):\n",
    "        for item_2 in basket[i + 1:]:\n",
    "            if all(item in freq_items for item in [item_1, item_2]):\n",
    "                key = (item_1, item_2) if item_1 < item_2 else (item_2, item_1)\n",
    "                val = [freq_items[item] for item in key] + [1]\n",
    "                pairs.append((key, tuple(val)))\n",
    "    return pairs\n",
    "\n",
    "def pair_conf(rdd):\n",
    "    items, support = rdd\n",
    "    i1, i2 = items\n",
    "    s1, s2, s12 = support\n",
    "    \n",
    "    # confidence is assymetrical, the denominator decides direction\n",
    "    # for each pair, get two confidence A -> B, A <- B\n",
    "    return [((i1, i2), s12 / s1), \n",
    "            ((i2, i1), s12 / s2)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conf(DAI93865 -> FRO40251) = 1.0000000000\n",
      "Conf(GRO85051 -> FRO40251) = 0.9991762768\n",
      "Conf(GRO38636 -> FRO40251) = 0.9906542056\n",
      "Conf(ELE12951 -> FRO40251) = 0.9905660377\n",
      "Conf(DAI88079 -> FRO40251) = 0.9867256637\n",
      "processing completed, time elapsed: 6.18s\n",
      "\n"
     ]
    }
   ],
   "source": [
    "time_start = time.time()\n",
    "\n",
    "# second pass\n",
    "pair_support = (sessions\n",
    "    .flatMap(build_pairs)\n",
    "    .reduceByKey(lambda x, y: (x[0], x[1], x[2] + y[2])))\n",
    "\n",
    "# warning: use all pairs to find rules, not just frequent pairs\n",
    "conf_pair = pair_support.flatMap(pair_conf)\n",
    "sorted_pair = sorted(conf_pair.collect(), key=lambda rdd : (-rdd[1], rdd[0][0]))\n",
    "with open('hw1_q2d.txt', 'w') as file:\n",
    "    for rel in sorted_pair[:5]:\n",
    "        (a, b), conf = rel\n",
    "        line = \"Conf(%s -> %s) = %.10f\"%(a, b, conf)\n",
    "        print(line)\n",
    "        file.write(line + \"\\n\")\n",
    "        \n",
    "time_end = time.time()\n",
    "print(\"processing completed, time elapsed: %.2fs\\n\"%(time_end - time_start))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Triples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_triples(l):\n",
    "    triples = []\n",
    "    if len(l) < 3: return triples\n",
    "    for i, item_1 in enumerate(l[:-2]):\n",
    "        for j in range(i + 1, len(l) - 1):\n",
    "            item_2 = l[j]\n",
    "            for item_3 in l[j + 1:]:\n",
    "                # sort triples in alphabetic order once, so that\n",
    "                # all 2-item permutation will be in alphabetic order\n",
    "                triple = tuple(sorted([item_1, item_2, item_3]))\n",
    "                \n",
    "                if all(item in freq_items for item in triple):\n",
    "                    pairs = [(triple[0], triple[1]), (triple[0], triple[2]), (triple[1], triple[2])]\n",
    "                    \n",
    "                    # construct triple only if all permutation of 2-iten pairs are frequent\n",
    "                    if all(pair in freq_pairs for pair in pairs):\n",
    "                            val = tuple([freq_pairs[pairs[0]], \n",
    "                                        freq_pairs[pairs[1]], \n",
    "                                        freq_pairs[pairs[2]], \n",
    "                                        1])\n",
    "                            triples.append((triple, val))\n",
    "    return triples\n",
    "\n",
    "def triple_conf(rdd):\n",
    "    items, support = rdd\n",
    "    i1, i2, i3 = items\n",
    "    s12, s13, s23, s123 = support\n",
    "    \n",
    "    # key is ordered such that A & B -> C\n",
    "    # not that A & B are already sorted since i1 < i2 < i3\n",
    "    return [((i1, i2, i3), s123 / s12), \n",
    "            ((i1, i3, i2), s123 / s13), \n",
    "            ((i2, i3, i1), s123 / s23)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conf(DAI23334, ELE92920 -> DAI62779) = 1.0000000000\n",
      "Conf(DAI31081, GRO85051 -> FRO40251) = 1.0000000000\n",
      "Conf(DAI55911, GRO85051 -> FRO40251) = 1.0000000000\n",
      "Conf(DAI62779, DAI88079 -> FRO40251) = 1.0000000000\n",
      "Conf(DAI75645, GRO85051 -> FRO40251) = 1.0000000000\n",
      "processing completed, time elapsed: 13.91s\n",
      "\n"
     ]
    }
   ],
   "source": [
    "time_start = time.time()\n",
    "\n",
    "# use frequent pair to build frequent triples\n",
    "freq_pair_support = pair_support.filter(lambda x : x[1][2] >= 100)\n",
    "freq_pairs = {x[0] : x[1][2] for x in freq_pair_support.collect()}\n",
    "\n",
    "# third pass: use all candidate triples to find rules, not just frequent triples\n",
    "conf_triple = (sessions\n",
    "    .flatMap(build_triples)\n",
    "    .reduceByKey(lambda x, y: (x[0], x[1], x[2], x[3] + y[3]))\n",
    "    .flatMap(triple_conf))\n",
    "\n",
    "sorted_triple = sorted(conf_triple.collect(), key=lambda rdd : (-rdd[1], rdd[0][0], rdd[0][1]))\n",
    "with open('hw1_q2e.txt', 'w') as file:\n",
    "    for rel in sorted_triple[:5]:\n",
    "        (a, b, c), conf = rel\n",
    "        line = \"Conf(%s, %s -> %s) = %.10f\"%(a, b, c, conf)\n",
    "        print(line)\n",
    "        file.write(line + \"\\n\")\n",
    "        \n",
    "time_end = time.time()\n",
    "print(\"processing completed, time elapsed: %.2fs\\n\"%(time_end - time_start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
